/** schedule.mb: contains implementation of scheduler functions
  * Currently, there isn't much of a scheduler: you can schedule and 
  * deschedule things on/off the run queue, but the scheduler has no notion of
  * who's running.  Some design is in order.
  *
  * All scheduler operations will require preemption to be disabled
  *
  * Author: Amanda M. Watson
  */
#include "schedule.mh"

/* 
 * global data structure: controls the run queue of runnable tcb's, 
 * denotes the tcb that is currently running, and whether preemption is enabled 
 */
static run_queue: rq_master = rq_master {
    run_Q: LIST_HEAD_INIT(run_queue.run_Q), 
    running: null,
    preempt_enabled: 0
}; 

fn preempt_disable() {
    run_queue.preempt_enabled = 0;
}

fn preempt_enable() {
    run_queue.preempt_enabled = 1;
}

fn is_preempt_enabled() -> u32 {
    run_queue.preempt_enabled
}

/* 
 * add a tcb to the run queue: position should be FRONT if tcb should be run immediately,
 * BACK if it should patiently wait its turn in the queue. 
 * Requires that tcb's state be set to NEW or RUNNABLE before insertion, so the
 * scheduler knows you really mean it.
 */
fn schedule(tcb: *tcb, pos: u32) {
    assert(is_preempt_enabled() == 0);
    assert(pos == FRONT || pos == BACK);   
 
    if (tcb->state == NEW) {
        set_state(tcb, RUNNABLE);
    }
    assert(tcb->state == RUNNABLE);
    if (pos == FRONT) {
        list_insert_head(&tcb->link, &(run_queue.run_Q));
        return ();
    } 
    if (pos == BACK) {
        list_insert_tail(&tcb->link, &(run_queue.run_Q));
        return ();
    }
    // pos should specify either the front or back position 
    assert(false);
}

/* Remove a tcb from the run queue */
fn unschedule(tcb: *tcb) {
    assert(is_preempt_enabled() == 0);
    assert(tcb->state == RUNNABLE);
    list_del(&(tcb->link))
} 

/* returns pointer to running tcb: later if we have aligned memory we can find it via TCB; for now, we keep
   a pointer in the scheduler */
fn get_tcb() -> *tcb {
    run_queue.running 
}

/* Replaces the running thread with the next thread in the run queue, and then
 * switches to this latest thread.  optionally takes in a state to assign the
 * currently running thread (if a running tcb's state is changed to MUT or COND,
 * for instance, it won't be re-added to the run queue) 
 * State is ignored if state == -1 */
fn scheduler_update(state: u32) {
    /* preemption must be disabled for this section, but we also want to enable
      * nesting */
    let is_pre_enabled = is_preempt_enabled();
    if (is_pre_enabled == 1) {
      preempt_disable(); 
    }
    
    /* the head of the run queue, if non-null is to be run next.  a
     * non-round-robin scheduler would likely change this */
    let new_running: *tcb = list_head_entry(&run_queue.run_Q, tcb, link);
    let old_running: *tcb = get_tcb();
     
    /* if there are no other threads in the run queue, continue with current
       thread and do not update */
    if (new_running != null) {
        
        if (is_pre_enabled == 1) {
            preempt_enable();
        }

        return();
    }

    /* if a state was provided, assign it to the running thread */
    if (state != -1) {
        assert(old_running != null);
        old_running->state = state;
    }

    if (old_running != null) {
        // TODO assert that the current stack pointer corresponds to a value on the
        // running tcb's kstack
        // TODO insert into sleep queue?
        if (old_running->state == RUNNABLE) {
            // we may want this to be "running" instead
            list_insert_tail(&old_running->link, &(run_queue.run_Q));
            run_queue.running = null;
        }
    } 

    assert(new_running != null); 
    list_del(&(new_running->link));
    run_queue.running = new_running;

    // TODO when we have VM in, we will need to switch address spaces

    context_switch(old_running, new_running); 
    
    if (is_pre_enabled == 1) {
        preempt_enable();
    }

}
