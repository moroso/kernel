/** tcb.mb: contains implementation of tcb-related functions.  Some changes will
 *  have to be made if the stack ends up growing up as was discussed
 *
 *  Author: Amanda M. Watson
 */

use consts::*;
use utils::list::*;
use locks::mutex::*;
use locks::cond::*;
use structures::proc::*;
use structures::tcb_dir::*;
use utils::buddy_alloc::{frame_alloc, frame_free};
use utils::stdlib::*;
use structures::schedule::{get_tcb, is_scheduled, scheduler_unlock,
                           preempt_enable};
use locks::rendezvous::*;
use structures::desc_table::*;
use arch::enable_interrupts;
use arch::thread::{context, fill_context};

fn tcb_init_func() {
    enable_interrupts();
    preempt_enable();
}

struct tcb {
    tid: u32,
    kstack_top: *u8,

    /*** ipc things ***/
    last_send: list_head,

    link: list_node, // used for putting on run queue
    proc_link: list_node,
    /*** tcb lookup directory ***/
    dir_link: list_node, // used for putting in tcb directory
    dir_ref: u32, // number of times the tcb is referenced via the directory

    /* some functions assign a state to let the program know what
     * the tcb should or shouldn't be doing (for instance, a TCB with state "COND"
     * should not be getting scheduled
     */
    state: u32,
    /* a pointer to the location on the kstack where the latest context was set
     * (occurs during context switch)
     */
    context: *context,
    proc: *proc,
    pid: i32,
}

/* tid-granting structures; ensures uniqueness and atomicity so that
 * every tcb gets a unique tid
 */
static tid_lock: kmut = KMUT_INIT!(tid_lock);
static tid_counter: u32 = 0;

/*
 * Atomically returns new tid for a tcb; all tids guaranteed to
 * be unique (barring overflow, if you wanna be all pedantic about it)
 */
fn new_tid() -> u32 {
    kmut_lock(&tid_lock);
    let tid: u32 = tid_counter;
    tid_counter+=1;
    kmut_unlock(&tid_lock);
    tid
}

fn get_tid() -> u32 {
    assert!(get_tcb() != null);
    get_tcb()->tid
}

/*
 * initializes an new tcb: sets top of kstack and assigns a tid.
 *
 * We assume that a tcb allocation is a page in
 * size; that way, we can allocate both the tcb and kstack at once, and both
 * will comprise exactly one page.
 */
fn tcb_init(tcb: *tcb) {
    tcb->kstack_top = (((tcb as u32) + PAGE_SIZE) - 4) as *u8;
    tcb->context = tcb->kstack_top as *context;
    tcb->state = STATE_NEW;
    tcb->dir_ref = 1; // we decrement by one when tcb goes away
    tcb->proc = null;
    tcb->tid = new_tid();
    list_init_node(&(tcb->link));
    list_init_node(&(tcb->dir_link));
    tcb->pid = -1;
    list_init_head(&tcb->last_send);
}


/* I don't know if we need this, so right now it's a placeholder */
fn tcb_destroy(tcb: *tcb) {
}

/*
 * Assigns a state to the given tcb; states
 * give us info about what the tcb is currently doing (MUT, for example, tells
 * us the tcb is currently in a mutex), which can be
 * helpful for debugging and providing guarantees.
 */
fn set_state(tcb: *tcb, state: u32) {
    tcb->state = state;
}

/* given a function, some data and its length, creates a new tcb that, when
 * switched to, executes function with a pointer to data as its argument */
fn thr_create(function: fn(*u8) -> (), data: *u8, len: u32) -> *tcb {

    let tcb: *tcb = frame_alloc() as *tcb;

    if (tcb == null) {
        return null;
    }

    tcb_init(tcb);

    assert!(tcb->kstack_top != null);

    /* make some room for the new context, the return function and its args */
    tcb->context = (tcb->kstack_top as u32 - sizeof(context) - len - 2 * sizeof(u32)) as *context;
    tcb->context->return_addr = function as u32;
    tcb->context->tcb_init_func = tcb_init_func as u32;
    // Fill out any arch-specific fields in the tcb's context.
    fill_context(tcb);

    /* place data onto the stack a place a pointer to data as an argument to
     * function */
    let arg_addr = ((&(tcb->context->return_addr) as u32) + 2 * sizeof(u32)) as *u32;
    let data_addr = (arg_addr+1) as *u32;

    mos_memcpy(data_addr, data as *u32, len);
    *arg_addr = data_addr as u32;
    tcb
}

/* for destroying tcbs that have never been scheduled/added to directory */
fn thr_abort(dead_tcb: *tcb) {
    assert!(dead_tcb != null);
    // ensure we are no longer on the run queue
    assert!(!is_scheduled(dead_tcb));
    // should be removed from directory first.  otherwise, deletion should be
    // done via ref count
    assert!(tcb_lookup(dead_tcb->tid) == null);
    frame_free(dead_tcb as *u8);
}

fn set_exit_status(proc: *proc, exit_status: u32) {
    assert!(proc != null);
    proc->exit_status->status = exit_status;
}
