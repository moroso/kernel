/* mailbox.mb
 * Contains kernelide functions and declarations for mailbox structure.  The
 * mailbox allows owners to receive messages, and non-owners to send them.  When
 * a reply is expected, the mailbox saves the sender's data in the receiving tcb
 * for future wakeup (either on cleanup when it exits the ipc function, or on reply)
 *
 * A mailbox is owned by the proc that creates it: all threads in that proc can
 * receive on the mailbox.  All other threads will return with error if they
 * attempt to receive
 *
 * children of the owner proc will be allowed to send to the mailbox, but are not
 * allowed to receive on it
 *
 * Mailboxes are reference counted: an entry in a descriptor table acts as a
 * reference.  Once all descriptors pointing to a mailbox have been removed --
 * meaning there is no longer any way for programs to communicate with it -- and
 * all lookups have ended, the mailbox is destroyed and freed.  
 *
 * We can think of the mailbox, to some extent, as the middle layer between the
 * rend primitive and the IPC functions
 *
 * NOTE: some language about whether the sender/receiver does the transfer will
 * be confusing without proper understanding of the rend synchronization
 * primitive.  See locks/rendezvous.mb for clarification.
 *
 * TODO we currently delete references for both sender and receiver, meaning
 * that the receiver deleting its mailbox does not wake up threads currently
 * waiting on it (though it does ensure no more threads are allowed to send to
 * it).  The code actually exists to wake up these threads with an error (at
 * which point they delete the descriptor in the table, provided it hasn't
 * already been replaced), but I haven't implemented it for the mailbox_remove
 * syscall because I haven't done enough testing to convince myself it works 
 *
 * Author: Amanda M. Watson
*/
use locks::rendezvous::*;
use structures::proc::*;
use structures::schedule::*;
use structures::desc_table::*;
use utils::slab_alloc::*;
use utils::list::*;
use structures::tcb::*;
use entry::get_ticks;

// the error that's returned if we attempt to wait on a mailbox we do not own
const MB_ERR_OWNER: i32 = -7;
// error internal to mailbox
const MB_ERR_INTERNAL: i32 = -8;
// incorrect dest mailbox
const MB_ERR_DEST: i32 = -9;

/* The mailbox structure: owners receive messages on a mailbox, while threads
 * with a descriptor that maps to the mailbox can send to them */
struct mailbox_t {
    // primitive that synchronizes senders
    // and receivers
    mb_rend: rend,
    // denotes the proc that owns the mailbox. only threads that belong to this
    // proc will be allowed to receive messages from the mailbox 
    owner: *proc,
    // denotes references: one reference for every open lookup
    // and descriptor table entry
    ref_count: u32,   
    // denotes whether the mailbox is accepting activity
    active: bool, 
}

/* create mailbox, add own proc as owner, add to desc table.
 * returns error if there is no room to add the descriptor
 * otherwise, returns new descriptor */
fn mb_init(mb: *mailbox_t, proc: *proc) -> i32 {
    assert!(proc != null);
    rend_init(&(mb->mb_rend));
    mb->owner = proc; 
    mb->active = true;
    mb->ref_count = 0;
    // attempt to add to descriptor table
    let ret = mb_table_add(&proc->mb_desc, mb);
    if (ret == DESC_ERR_INTERNAL) {
        ret = MB_ERR_INTERNAL;
    }
    if (ret == 0) {
        assert!(mb->ref_count == 1);
    }

    ret
}

/* 
 *  When a thread invokes mb_send on a mailbox mb, it blocks until either it times out, or
 *  a receiving thread calls mb_recv on mb. 
 * 
 *  if rend_wait returns a non-null rend_node, it means that a receiver is blocked
 *  on us (the invoking thread), and we are responsible for the message transfer
 *  once we exit mb_send.  we denote this case by returning the receiver's tcb.
 *  mb_send also stores the rend_node in the tcb (last_send), so it can be
 *  reawoken when mb_end_send is called.
 *
 *  If the return value of rend_wait is null, this means the receiver has already
 *  performed the transfer and is not blocked on us.  We denote this by
 *  returning null
 *
 * - desc: the descriptor for the mailbox the invoking thread is waiting on.  returns with err
 *   MB_ERR_DEST if the mailbox lookup fails
 * - message: the message being send to the sender.  This message can contain
 *   whatever info is necessary for the sender thread to know how to treat a
 *   sleeping receiver.  
 * - message_len: lenth of message.  mailboxes require a non-zero message length 
 * - message_recv: pointer where message left by sender can be stored.  In the
 *   case of mailboxes, a non-empty message denotes that the invoking thread's
 *   message has been received and handled.  Otherwise, we are receiving the
 *   request of the sender
 * - recv_len: pointer to where receiver length is stored.  The value at
 *   recv_len is updated to denote the legnth of the message at message_recv
 * - timeout: how many cycles the invoking thread should block in wait of a
 *   transfer before returning with error.  Note that thread is unable to time
 *   out while the sending thread is performing the transfer.
 * - err: stores any errors that arise; *err = 0 means receipt was successful
 * 
 * Returns the reciever's tcb if a rend_node is retrieved; null otherwise 
 */

fn mb_send(desc: u32, message: *u32, message_len: u32, message_recv: **u32,
        recv_len: *u32, timeout: u32, option: u32, err: *i32 , table:
        *mb_desc_table) -> *tcb {

    if (table != &get_tcb()->proc->mb_desc) {
        assert!(option == SEND_ASYNC);
    }

    *err = 0;
    let mb = mb_desc_lookup(desc, table);
    if (mb == null) {
        *err = MB_ERR_DEST;
        return null;
    }

    if (!(mb->active)) {

        *err = MB_ERR_DEST;
        mb_table_dead_entry_remove(desc, mb);   
        mb_end_lookup(mb);

        return null;
    }

    if (timeout != -1) { 
        timeout = timeout + get_ticks();
    }

    let ret = rend_wait(&mb->mb_rend, message, message_len, message_recv, recv_len, timeout,
            option, err);

    // if the mailbox died while we were waiting on it, remove the entry from
    // our table (check that it's the same as when we did the lookup, to make
    // sure another thread didn't alter it
    if (*err == REND_ERR_DEAD) {
        mb_table_dead_entry_remove(desc, mb);                        
        mb_end_lookup(mb);
        return null;
    }

    if (ret != null) {
        assert!(*err == 0);
        assert!(ret->option == RECV);
        list_insert_head(&ret->rend_link, &(get_tcb()->last_send));
        assert!(ret->can_timeout == false || ret->timeout ==
                -1);
        *recv_len = ret->message_len;
        *message_recv = ret->message;
        assert!(ret->tcb != null);
        mb_end_lookup(mb);

        return ret->tcb;
    }  

    // if ret is null, this means any message has already been transferred to
    // message_recv during rend_wait
    mb_end_lookup(mb);
    null
}

/* Cleanup in the case that a thread calls mb_send and retrieves a non-null
 * tcb.  Should be invoked once long transfer from receiver to sender is
 * complete. wakes up receiver while passing it a short message
 *
 * - message: short message being passed to receiver
 * - message_len: length of message
 * - err: error code to send the receiver (denotes whether transfer was successful)
 *
 * Returns immediately if no sender if waiting to be woken up
 * */
fn mb_end_send(message: *u32, message_len: u32, err: i32) {
    if (list_is_empty(&get_tcb()->last_send)) {
        assert!(message_len == 0);
        return ();
    }

    let last_send: *rend_node = list_head_entry!(&get_tcb()->last_send, rend_node,
            rend_link);
    assert!(last_send->option == RECV);
    assert!(last_send->can_timeout == false);
    list_del(&last_send->rend_link);
    rend_signal(message, message_len, last_send, err);

}


/* 
 *  When an owner thread invokes mb_recv on a mailbox mb, it blocks until either it times out, or
 *  a sending thread calls mb_send on mb. 
 * 
 *  if rend_wait returns a non-null rend_node, it means that a sender is blocked
 *  on us (the invoking thread), and we are responsible for the message transfer
 *  once we exit mb_recv.  we denote this case by returning the sender's tcb.
 *  mb_recv also stores the rend_node in the tcb (last_send), so it can be
 *  reawoken (or at least allowed to time out) when mb_end_recv is called.
 *
 *  If the return value of rend_wait is null, this means the sender has already
 *  performed the transfer and is not blocked on us.  We denote this by
 *  returning null
 *
 * - desc: the descriptor for mailbox the invoking thread is waiting on.  returns with err
 *   MB_ERR_OWNER if thread's proc is not the owner of mb, and MB_ERR_DEST if
 *   the mailbox lookup fails
 * - message: the message being send to the sender.  This message is defined by
 *   the programmer, and can contain
 *   whatever info is necessary for the sender thread to know how to treat a
 *   sleeping receiver.  
 * - message_len: length of message.  
 * - message_recv: pointer where message left by sender can be stored.  
 * - recv_len: pointer to where receiver length is stored.  The value at
 *   recv_len is updated to denote the legnth of the message at message_recv
 * - option: returns whether the type of message being received is SEND_SYNC,
 *   SEND_SYNC_NOREPLY, or SEND_ASYNC
 * - timeout: how many cycles the invoking thread should block in wait of a
 *   transfer before returning with error.  Note that thread is unable to time
 *   out while the sending thread is performing the transfer.
 * - err: stores any errors that arise; *err = 0 means receipt was successful
 * 
 *  Barring errors, returns the tcb of the sender if we're responsible for the transfer.  null if
 *  the transfer already happened. 
 *
 *  It's important to note that if the return value is non-null and its option
 *  is not SEND_ASYNC, this means the
 *  sending thread is waiting to be woken up (or at least have its timeout
 *  restarted) by mb_end_recv(); it is incorrect to leave a function that calls
 *  mb_recv and retrieves a message without knowing when the thread will call mb_end_recv;
 *
 *  Further note that just because a tcb is returned, it does not mean the tcb is
 *  blocked.  in the async case, the tcb returned could be active.  look at
 *  option to determine whether the returned tcb is in an active state
 * 
 */
fn mb_recv(desc: u32, message: *u32, message_len: u32, message_recv: **u32,
        recv_len: *u32, timeout: u32, option: *u32, err: *i32) -> *tcb {

    assert!(option != null && err != null);

    /* look up mailbox in descriptor table */
    let mb = mb_desc_lookup(desc, &(get_tcb()->proc->mb_desc));
    if (mb == null) {
        *err = MB_ERR_DEST;
        return null;
    }

    /* if mailbox is not longer active (sender removed reference), return with
     * error */ 
    if (!(mb->active)) {
        *err = MB_ERR_INTERNAL;
        mb_end_lookup(mb);
        return null;
    }

    if (timeout != -1) { 
        timeout = timeout + get_ticks();
    }

    assert!(list_is_empty(&get_tcb()->last_send));

    if (get_tcb()->proc != mb->owner) {
        *err = MB_ERR_OWNER;         
        mb_end_lookup(mb);
        return null;
    }
    let ret = rend_wait(&mb->mb_rend, message, message_len, message_recv, recv_len, timeout,
            RECV, err);

    /* if we need to wake up our sender after we return, store sender in the
     * tcb with its timeout disabled (note that since this is per-threadm we
     * don't have to deal with locking since it cannot timeout) */
    if (ret != null) {
        assert!(ret->option != RECV);
        list_insert_head(&ret->rend_link, &(get_tcb()->last_send));
        assert!(ret->can_timeout == false || ret->timeout ==
                -1);
        *recv_len = ret->message_len;
        *message_recv = ret->message;
        *option = ret->option;
        assert!(ret->tcb != null);

        mb_end_lookup(mb);
        return ret->tcb;
    } 
    // if ret is null, this means any message has already been transferred to
    // message_recv during rend_wait

    mb_end_lookup(mb);
    null
}

/* Cleanup in the case that a thread calls mb_recv and retrieves a non-null
 * tcb.  Should be invoked once transfer from sender to receiver is
 * complete.  If the sender does not expect a reply, wakes it up
 * immediately; otherwise, it sets can_timeout to true, allowing the sender to
 * timeout and return if the receiver takes to long to reply
 *
 * Note that this function must still be called if a message is async
 *
 * - err: error code to send the sender (denotes whether transfer was successful)
 *
 * Returns immediately if no sender if waiting to be woken up
 * */
fn mb_end_recv(err: i32) {

    if (list_is_empty(&get_tcb()->last_send)) {
        return ();
    }

    let last_send: *rend_node = list_head_entry!(&get_tcb()->last_send, rend_node,
            rend_link);

    /* if no reply is expected, remove rend_node from tcb and signal it with err */
    if (last_send->option != SEND_SYNC_REPLY || err < 0) {
        assert!(last_send->can_timeout == false);
        list_del(&last_send->rend_link);
        rend_signal(null, 0, last_send, err);
    } else {
        /* if waiting sender expects a reply, don't wake them up; rather re-enable
         * timeout and return */
        assert!(last_send->tcb != null); 
        assert!(last_send->can_timeout == false || last_send->timeout ==
                -1);
        last_send->can_timeout = true;
    }

}

/* destroys a mailbox; wakes up all waiting threads with an error and frees the
 * mailbox.  Assumes mailbox ref_count is 0 */
fn mb_destroy(mb: *mailbox_t) {
    mb->active = false;
    rend_destroy(&mb->mb_rend, REND_ERR_DEAD);
    assert!(mb->ref_count == 0);
    mb->owner = null; 
    slub_free(mb as *u32, sizeof(mailbox_t));
}

/* removes last_send from location in tcb so that invoking thread can reply to
 * it.  sets timeout flag to false, and atomically removes the node.  returns
 * null if no node exists */
fn last_send_remove() -> *rend_node {
    let enable = cond_preempt_disable();
    if (list_is_empty(&get_tcb()->last_send)) {
        cond_preempt_enable(enable);
        return null;
    }

    let last_send: *rend_node = list_head_entry!(&get_tcb()->last_send, rend_node,
            rend_link);
    assert!(last_send != null);
    last_send->can_timeout = false;
    list_del(&last_send->rend_link);
    cond_preempt_enable(enable);
    last_send
}

/* restore a node removed from last_send.  used to handle errors in ipc_reply */
fn last_send_unremove(node: *rend_node) {
    list_insert_head(&node->rend_link, &(get_tcb()->last_send));
    assert!(node->can_timeout == false || node->timeout ==
            -1);
    node->can_timeout = true;
}
