/* 
 *
 * Author: Amanda M. Watson
*/
use locks::rendezvous::*;
use structures::proc::*;
use structures::schedule::*;
use ipc::desc_table::*;
use utils::slab_alloc::*;
use utils::list::*;

const ERR_OWNER: i32 = -7;

struct mailbox_t {
    mb_rend: rend,
    owner: *proc,
    ref_count: u32, // denotes how many desc tables have references
    active: bool, 
}

fn mailbox_new() -> i32 {
    let mb = slub_alloc(sizeof(mailbox_t)) as *mailbox_t; 
    if (mb == null) {
        return -1;
    }
    let ret: i32 = mb_init(mb, get_tcb()->proc);
    ret

}

// create mailbox, add own proc as owner, add to desc table.
// returns error if there is no room to add the descriptor
// otherwise, returns new descriptor
fn mb_init(mb: *mailbox_t, proc: *proc) -> i32 {
    assert!(proc != null);
    rend_init(&(mb->mb_rend));
    mb->owner = proc; 
    mb->active = true;
    mb->ref_count = 0;
    let ret = mb_table_add(&proc->mb_desc, mb);
    assert!(mb->ref_count == 1);
    ret
}

// TODO we can probably encapsulate the rend_node business if we're careful
fn mb_recv(mb: *mailbox_t, message: *u32, message_len: u32, message_recv: **u32,
        recv_len: *u32, timeout: u32, err: *i32) -> *rend_node {

    assert!(list_is_empty(&get_tcb()->last_send));

    if (get_tcb()->proc != mb->owner) {
        *err = ERR_OWNER; // TODO send this error to user
        return null;
    }
    let ret = rend_wait(&mb->mb_rend, message, message_len, message_recv, recv_len, timeout,
            RECV, err);

    if (ret != null) {
        list_insert_head(&ret->rend_link, &(get_tcb()->last_send));
        assert!(ret->can_timeout == false || ret->timeout ==
                -1);
    }

    ret
}

fn mb_end_recv(err: i32) {

    if (list_is_empty(&get_tcb()->last_send)) {
        return ();
    }

    let last_send: *rend_node = list_head_entry!(&get_tcb()->last_send, rend_node,
            rend_link);

    if (last_send->option != SEND_SYNC_REPLY || err < 0) {
        assert!(last_send->can_timeout == false);
        list_del(&last_send->rend_link);
        rend_signal(null, 0, last_send, err);
    } else {
        assert!(last_send->tcb != null);
        assert!(last_send->can_timeout == false || last_send->timeout ==
                -1);
        last_send->can_timeout = true;
    }

}

fn mb_send(mb: *mailbox_t, message: *u32, message_len: u32, message_recv: **u32,
        recv_len: *u32, timeout: u32, option: u32, err: *i32) -> *rend_node {

    let ret = rend_wait(&mb->mb_rend, message, message_len, message_recv, recv_len, timeout,
            option, err);

     if (ret != null) {
        list_insert_head(&ret->rend_link, &(get_tcb()->last_send));
        assert!(ret->can_timeout == false || ret->timeout ==
                -1);
    }
    ret
}

fn mb_end_send(message: *u32, message_len: u32, err: i32) {
    if (list_is_empty(&get_tcb()->last_send)) {
        assert!(message_len == 0);
        return ();
    }

    let last_send: *rend_node = list_head_entry!(&get_tcb()->last_send, rend_node,
            rend_link);
    assert!(last_send->option == RECV);
    assert!(last_send->can_timeout == false);
    list_del(&last_send->rend_link);
    rend_signal(message, message_len, last_send, err);

}

fn mb_destroy(mb: *mailbox_t) {
    mb->active = false;
    rend_destroy(&mb->mb_rend, REND_ERR_DEAD);
    assert!(mb->ref_count == 0);
    mb->owner = null; 
    slub_free(mb as *u32, sizeof(mailbox_t));
}
