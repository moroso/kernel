/* Memory allocator -- whee ("slab allocator")
 * a very simple slab allocator.  the basic allocation function
 * searches a list of sorted, sized "caches" for the bucket size that is the
 * closest fit to the allocation.
 *
 *   each cache contains a list of elements cut
 * from one or more "slabs": large, contiguous chunks of memory handed to us by
 * the buddy allocator
 *
 * users can also create caches for memory chunks of uniform size; however, we
 * are not currently preserving struct initialization
 *
 * In order for this to actually work, we will need globals
 * TODO remove slabs when they are freed
 *
 * Author: Amanda M. Watson
 */

use consts::*;
use list::*;
use utils::buddy_alloc::{frame_alloc,frame_alloc_pow2};

const SLAB_SIZE: u32 = PAGE_SIZE; /* this really isn't the right size*/
const UINT_SIZE: u32 = 4;
const POWER_MIN: u32 = 2;
const POWER_MAX: u32 = 9;

struct slab_descriptor {
slab: *u32,
    slab_low: *u32,
    element_count: u32,
    slab_link: list_node,
}

struct cache_descriptor {
size: u32,
    slab: *u32,
    link: list_node,
}

static head: list_head = LIST_HEAD_INIT!(head);
static caches: *cache_descriptor = null;

fn slab_add(size: u32, cache: *cache_descriptor) {
    let slab: *u32 = frame_alloc() as *u32;
    if (slab == null) {
        return ();
    }
    /* divide into elements */
    let node_prev: *u32 = slab;
    let i: u32;
    for (i = size; i < SLAB_SIZE; i+=size) {
        let node: *u32 = ((node_prev as u32) + size) as *u32;
        *node_prev = node as u32;
        node_prev = node;
    }
    *node_prev = 0;
    let node: *u32 = slab;
    /* ensure that we have the correct number of elements and that they are each
     * an offset of size away from each other */
    i = 0;
    while (node != null) {
        assert (!(*node - (node as u32) != size && *node != 0));
        
        node = *node as *u32;
        i+=1;
    };

    /* should divide evenly */
    assert (i == (SLAB_SIZE/size));
    cache->slab = slab;
}

/* returns the index of the correct cache for the given size */
fn find_cache(size: u32) -> i32 {
    let power: u32;
    for (power = POWER_MIN; power <= POWER_MAX; power +=1) {
        if (size <= (1 << power)) {
            return (power - POWER_MIN) as i32;
        }
    }
    -1
}

/* creates a cache with a single slab, full of size-sized elements */
fn cache_create(size: u32, cache: *cache_descriptor) -> i32 {
    /* ensure this is a power of two */
    assert (size&1 != 1 && size >= UINT_SIZE);
    cache->size = size;
    slab_add(size, cache);
    if (cache->slab == null) {
        return -1;
    }
    0
}

/* remove an element from the given cache.  if cache is empty, a new slab is
 * allocated  */
fn cache_remove (cache: *cache_descriptor) -> *u32 {
    if (cache->slab == null) {
        slab_add(cache->size, cache);
    }

    let element: *u32 = cache->slab;
    if (element != null) {
        cache->slab = *element as *u32;
    }
    element
}

/* add element back into cache */
fn cache_add (element: *u32, cache: *cache_descriptor) {
    /* TODO check memory bounds */
    *element = cache->slab as u32;
    cache->slab = element;
}

fn slub_init() {
    // we are doing this sham of an allocation because we can't have a sized
    // array as a global, due to the compiler's initialization requirement.
    // Would like if fix.
    caches = frame_alloc() as *cache_descriptor;
    let i: u32;
    for (i = POWER_MIN; i <= POWER_MAX; i+=1) {
        let cache = &caches[i - POWER_MIN];
        cache_create(1 << i, cache);
    }
}

/* NOTE: does NOT support sizes larger than a slab.  For that, you will want to
 * use frame_alloc */
fn slub_alloc(size: u32) -> *u32 {
    let cache_num: i32 = find_cache(size);
    if (cache_num == -1) {
        return null;
    }
    cache_remove(&(caches[cache_num as u32]))
}

fn slub_free(element: *u32, size: u32) {
    let cache_num: i32 = find_cache(size);
    if (cache_num == -1) {
        return ();
    }
    cache_add(element, &(caches[cache_num as u32]))
}
